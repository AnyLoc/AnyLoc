{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnyLoc/AnyLoc/blob/main/demo/anyloc_vlad_generate_colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnyLoc VLAD DINOv2 Descriptors\n",
    "\n",
    "Given a folder of images, this notebook generates global descriptors per image and stores the result in another folder. The global descriptors are created using VLAD over DINOv2 features from a particular layer and facet of transformer (default is from the paper).\n",
    "\n",
    "We'll use images from [FAB-MAP: Probabilistic Localization and Mapping in the Space of Appearance](https://www.robots.ox.ac.uk/~mobile/IJRR_2008_Dataset/) (data from [here](https://www.robots.ox.ac.uk/~mobile/IJRR_2008_Dataset/data.html)) as an example. This will be downloaded if it doesn't exist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab\n",
    "\n",
    "- Run this section only if running this notebook on Google Colab.\n",
    "- If you're running this section on your local machine, jump to `Downloading data` sub-section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found utilities.py\n"
     ]
    }
   ],
   "source": [
    "# Ensure that utilities.py module is there\n",
    "import os\n",
    "import requests\n",
    "if os.path.isfile('utilities.py'):\n",
    "    print('Found utilities.py')\n",
    "else:\n",
    "    print(\"Could not find utilities.py, downloading it\")\n",
    "    url = \"https://raw.githubusercontent.com/AnyLoc/AnyLoc/main/demo/utilities.py\"\n",
    "    file_data = requests.get(url, allow_redirects=True)\n",
    "    with open('utilities.py', 'wb') as handler:\n",
    "        handler.write(file_data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying NVIDIA GPU is available\n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-e356fcd4-1d44-a564-e38c-d5c80c7a1b2e)\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-5d97153c-baaa-6e31-90f3-1dd2a2dda19d)\n",
      "Please see that the GPU has at least 16 GB VRAM free\n",
      "Thu Aug 17 18:23:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 36%   29C    P8    16W / 250W |      0MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 36%   26C    P8    21W / 250W |   7322MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A      8170      C   python                           7319MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying NVIDIA GPU is available\")\n",
    "!nvidia-smi -L\n",
    "print(\"Please see that the GPU has at least 16 GB VRAM free\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that packages are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install other things\n",
    "print(\"Trying to access utility libraries\")\n",
    "try:\n",
    "    import einops\n",
    "    import fast_pytorch_kmeans\n",
    "    import distinctipy\n",
    "    import onedrivedownloader\n",
    "    print(\"Can access utility libraries\")\n",
    "except ImportError:\n",
    "    print(\"Installing utility libraries\")\n",
    "    !pip install fast_pytorch_kmeans\n",
    "    !pip install einops\n",
    "    !pip install distinctipy\n",
    "    !pip install onedrivedownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Data\n",
    "\n",
    "Downloading\n",
    "\n",
    "- `cache`: Vocabulary (cluster centers) and test images\n",
    "- `data`: Images that we'll use for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache folder already exists!\n"
     ]
    }
   ],
   "source": [
    "# Download cache data from OneDrive\n",
    "from onedrivedownloader import download\n",
    "from utilities import od_down_links\n",
    "# Link\n",
    "ln = od_down_links[\"cache\"]\n",
    "# Download and unzip\n",
    "if os.path.isdir(\"./cache\"):\n",
    "    print(\"Cache folder already exists!\")\n",
    "else:\n",
    "    print(\"Downloading the cache folder\")\n",
    "    download(ln, filename=\"cache.zip\", unzip=True, unzip_path=\"./\")\n",
    "    print(\"Cache folder downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images from OneDrive ...\n",
      "Unzipping file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files: 100%|██████████| 2475/2475 [00:00<00:00, 140176.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and extraction of images from OneDrive completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the data (images)\n",
    "use_odrive = True   # If True, use personal OneDrive (not official links)\n",
    "if use_odrive:\n",
    "    print(\"Downloading images from OneDrive ...\")\n",
    "    imgs_link = od_down_links[\"test_imgs_od\"]\n",
    "    download(imgs_link, \"./data/CityCenter/Images.zip\", unzip=True, unzip_path=\"./data/CityCenter\")\n",
    "    print(\"Download and extraction of images from OneDrive completed\")\n",
    "else:\n",
    "    print(\"Downloading from original source\")\n",
    "    imgs_link = od_down_links[\"test_imgs\"]\n",
    "    if os.path.isdir(\"./data/CityCenter\"):\n",
    "        print(\"Directory already exists\")\n",
    "    else:\n",
    "        os.makedirs(\"./data/CityCenter\")\n",
    "        print(\"Directory created\")\n",
    "    !wget $imgs_link -O ./data/CityCenter/Images.zip\n",
    "    print(\"Extraction completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2474 images in /scratch/avneesh.mishra/vl-vpr/apps/global_descriptors/data/CityCenter/Images\n"
     ]
    }
   ],
   "source": [
    "# Ensurer that everything went smoothly\n",
    "import glob\n",
    "_ex = lambda x: os.path.realpath(os.path.expanduser(x))\n",
    "cache_dir: str = _ex(\"./cache\")\n",
    "imgs_dir = _ex(\"./data/CityCenter/Images/\")\n",
    "assert os.path.isdir(cache_dir), \"Cache directory not found\"\n",
    "assert os.path.isdir(imgs_dir), \"Invalid unzipping\"\n",
    "num_imgs = len(glob.glob(f\"{imgs_dir}/*.jpg\"))\n",
    "print(f\"Found {num_imgs} images in {imgs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as tvf\n",
    "from torchvision.transforms import functional as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import distinctipy as dipy\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Literal, List\n",
    "import os\n",
    "import natsort\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "# DINOv2 imports\n",
    "from utilities import DinoV2ExtractFeatures\n",
    "from utilities import VLAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Global Descriptors\n",
    "\n",
    "Save global descriptors as numpy arrays to a directory (mirroring the directory structure of the dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program parameters\n",
    "save_dir = _ex(\"./data/CityCenter/GD_Images/\")\n",
    "device = torch.device(\"cuda\")\n",
    "# Dino_v2 properties (parameters)\n",
    "desc_layer: int = 31\n",
    "desc_facet: Literal[\"query\", \"key\", \"value\", \"token\"] = \"value\"\n",
    "num_c: int = 32\n",
    "# Domain for use case (deployment environment)\n",
    "domain: Literal[\"aerial\", \"indoor\", \"urban\"] = \"urban\"\n",
    "# Maximum image dimension\n",
    "max_img_size: int = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /scratch/avneesh.mishra/vl-vpr/apps/global_descriptors/data/CityCenter/GD_Images\n"
     ]
    }
   ],
   "source": [
    "# Ensure inputs are fine\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    print(f\"Creating directory: {save_dir}\")\n",
    "else:\n",
    "    print(\"Save directory already exists, overwriting possible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DINOv2 Extractor\n",
    "\n",
    "DINOv2 extractor and the base transformation (for each image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home2/avneesh.mishra/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "# DINO extractor\n",
    "if \"extractor\" in globals():\n",
    "    print(f\"Extractor already defined, skipping\")\n",
    "else:\n",
    "    extractor = DinoV2ExtractFeatures(\"dinov2_vitg14\", desc_layer,\n",
    "        desc_facet, device=device)\n",
    "# Base image transformations\n",
    "base_tf = tvf.Compose([\n",
    "    tvf.ToTensor(),\n",
    "    tvf.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                    std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLAD object\n",
    "\n",
    "For forming global descriptors. Also loads the cluster centers (vocabulary) for VLAD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that data is present\n",
    "ext_specifier = f\"dinov2_vitg14/l{desc_layer}_{desc_facet}_c{num_c}\"\n",
    "c_centers_file = os.path.join(cache_dir, \"vocabulary\", ext_specifier,\n",
    "                            domain, \"c_centers.pt\")\n",
    "assert os.path.isfile(c_centers_file), \"Cluster centers not cached!\"\n",
    "c_centers = torch.load(c_centers_file)\n",
    "assert c_centers.shape[0] == num_c, \"Wrong number of clusters!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cache directory already exists: /scratch/avneesh.mishra/vl-vpr/apps/images_vlad_clusters/cache/vocabulary/dinov2_vitg14/l31_value_c32/urban\n",
      "Using cached cluster centers\n",
      "Desc dim set to 1536\n"
     ]
    }
   ],
   "source": [
    "# VLAD object\n",
    "vlad = VLAD(num_c, desc_dim=None, \n",
    "        cache_dir=os.path.dirname(c_centers_file))\n",
    "# Fit (load) the cluster centers (this'll also load the desc_dim)\n",
    "vlad.fit(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Descriptor Generation\n",
    "\n",
    "Main generation stage. Creating global descriptors only for the first 20 images here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11efbc7974c54f3b93265a81666820d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_fnames = glob.glob(f\"{imgs_dir}/*.jpg\")\n",
    "img_fnames = natsort.natsorted(img_fnames)\n",
    "for img_fname in tqdm(img_fnames[:20]):\n",
    "    # DINO features\n",
    "    with torch.no_grad():\n",
    "        pil_img = Image.open(img_fname).convert('RGB')\n",
    "        img_pt = base_tf(pil_img).to(device)\n",
    "        if max(img_pt.shape[-2:]) > max_img_size:\n",
    "            c, h, w = img_pt.shape\n",
    "            # Maintain aspect ratio\n",
    "            if h == max(img_pt.shape[-2:]):\n",
    "                w = int(w * max_img_size / h)\n",
    "                h = max_img_size\n",
    "            else:\n",
    "                h = int(h * max_img_size / w)\n",
    "                w = max_img_size\n",
    "            print(f\"To {(h, w) =}\")\n",
    "            img_pt = T.resize(img_pt, (h, w), \n",
    "                    interpolation=T.InterpolationMode.BICUBIC)\n",
    "            print(f\"Resized {img_fname} to {img_pt.shape = }\")\n",
    "        # Make image patchable (14, 14 patches)\n",
    "        c, h, w = img_pt.shape\n",
    "        h_new, w_new = (h // 14) * 14, (w // 14) * 14\n",
    "        img_pt = tvf.CenterCrop((h_new, w_new))(img_pt)[None, ...]\n",
    "        # Extract descriptor\n",
    "        ret = extractor(img_pt) # [1, num_patches, desc_dim]\n",
    "    # VLAD global descriptor\n",
    "    gd = vlad.generate(ret.cpu().squeeze()) # VLAD: shape [agg_dim]\n",
    "    gd_np = gd.numpy()[np.newaxis, ...] # shape: [1, agg_dim]\n",
    "    np.save(f\"{save_dir}/{os.path.basename(img_fname)}.npy\", gd_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl-vpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
